{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ea125b-87e4-4f99-bd4f-9293bb20879d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_name_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mpredict(y)\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe decrypted message is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, ascii_decode(y_hat))\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _name_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_main_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    120\u001b[0m     main()\n",
      "\u001b[1;31mNameError\u001b[0m: name '_name_' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Reshape, Conv2D, Concatenate, TimeDistributed, Dense\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import TensorSpec, float32, int32\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def rand_img(size):\n",
    "    return np.random.randint(0, 256, size).astype(np.float32) / 255.0\n",
    "\n",
    "def rand_sentence(len, max):\n",
    "    return np.random.randint(0, max, len).astype(np.int32)\n",
    "\n",
    "def one_hot_encoding(sentence, max):\n",
    "    msg = np.zeros((len(sentence), max), dtype=np.float32)\n",
    "    for i, v in enumerate(sentence):\n",
    "        msg[i, v] = 1.0\n",
    "    return msg\n",
    "\n",
    "def data_generator(image_size, sentence_len, sentence_max_word, batch_size=32):\n",
    "    while True:\n",
    "        x_img = np.zeros((batch_size, image_size[0], image_size[1], image_size[2]), dtype=np.float32)\n",
    "        x_sen = np.zeros((batch_size, sentence_len), dtype=np.int32)\n",
    "        y_img = np.zeros((batch_size, image_size[0], image_size[1], image_size[2]), dtype=np.float32)\n",
    "        y_sen = np.zeros((batch_size, sentence_len, sentence_max_word), dtype=np.float32)\n",
    "        for i in range(batch_size):\n",
    "            img = rand_img(image_size)\n",
    "            sentence = rand_sentence(sentence_len, sentence_max_word)\n",
    "            sentence_one_hot_encoded = one_hot_encoding(sentence, sentence_max_word)\n",
    "            x_img[i] = img\n",
    "            x_sen[i] = sentence\n",
    "            y_img[i] = img\n",
    "            y_sen[i] = sentence_one_hot_encoded\n",
    "        yield (x_img, x_sen), (y_img, y_sen)\n",
    "\n",
    "def get_model(image_shape, sentence_len, max_word):\n",
    "    input_img = Input(image_shape)\n",
    "    input_sen = Input((sentence_len,))\n",
    "    embed_sen = Embedding(max_word, 100)(input_sen)\n",
    "    flat_emb_sen = Flatten()(embed_sen)\n",
    "    flat_emb_sen = Dense(image_shape[0] * image_shape[1] * 3)(flat_emb_sen)\n",
    "    flat_emb_sen = Reshape((image_shape[0], image_shape[1], 3))(flat_emb_sen)\n",
    "    trans_input_img = Conv2D(20, 1, activation=\"relu\")(input_img)\n",
    "    enc_input = Concatenate(axis=-1)([flat_emb_sen, trans_input_img])\n",
    "    out_img = Conv2D(3, 1, activation='relu', name='image_reconstruction')(enc_input)\n",
    "    decoder_model = Sequential(name=\"sentence_reconstruction\")\n",
    "    decoder_model.add(Input(shape=(100, 100, 3)))\n",
    "    decoder_model.add(Conv2D(1, 1))\n",
    "    decoder_model.add(Reshape((sentence_len, 100)))\n",
    "    decoder_model.add(TimeDistributed(Dense(max_word, activation=\"softmax\")))\n",
    "    out_sen = decoder_model(out_img)\n",
    "    model = Model(inputs=[input_img, input_sen], outputs=[out_img, out_sen])\n",
    "    model.compile(optimizer='adam', loss=[MeanAbsoluteError(), CategoricalCrossentropy()],\n",
    "                  metrics={'sentence_reconstruction': CategoricalAccuracy()})\n",
    "    encoder_model = Model(inputs=[input_img, input_sen], outputs=[out_img])\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "def ascii_encode(message, sentence_len):\n",
    "    sen = np.zeros((1, sentence_len), dtype=np.int32)\n",
    "    for i, a in enumerate(message.encode(\"ascii\")):\n",
    "        sen[0, i] = a\n",
    "    return sen\n",
    "\n",
    "def ascii_decode(message):\n",
    "    return ''.join(chr(int(a)) for a in message[0].argmax(-1))\n",
    "\n",
    "def main():\n",
    "    image_shape = (100, 100, 3)\n",
    "    sentence_len = 100\n",
    "    max_word = 256\n",
    "    batch_size = 64\n",
    "    \n",
    "    gen = data_generator(image_shape, sentence_len, max_word, batch_size)\n",
    "    \n",
    "    output_signature = (\n",
    "        (TensorSpec(shape=(batch_size, *image_shape), dtype=float32),\n",
    "         TensorSpec(shape=(batch_size, sentence_len), dtype=int32)),\n",
    "        (TensorSpec(shape=(batch_size, *image_shape), dtype=float32),\n",
    "         TensorSpec(shape=(batch_size, sentence_len, max_word), dtype=float32))\n",
    "    )\n",
    "    \n",
    "    dataset = Dataset.from_generator(lambda: gen, output_signature=output_signature)\n",
    "    \n",
    "    model, encoder, decoder = get_model(image_shape, sentence_len, max_word)\n",
    "    try:\n",
    "        model.load_weights(\"best_weights.weights.h5\")\n",
    "    except:\n",
    "        model.fit(dataset, epochs=10, steps_per_epoch=100, callbacks=[\n",
    "            ModelCheckpoint(\"best_weights.weights.h5\", monitor=\"loss\",\n",
    "                            verbose=1,\n",
    "                            save_weights_only=True,\n",
    "                            save_best_only=True)]\n",
    "        )\n",
    "    \n",
    "    img_temp = Image.open(\"download.png\").convert(\"RGB\")  # Ensure image is in RGB format\n",
    "    res = img_temp.resize((100, 100))\n",
    "    img = np.expand_dims(img_to_array(res) / 255.0, axis=0)  # Normalized image array\n",
    "    \n",
    "    text_to_encode = input(\"Enter the code you want to encode: \")\n",
    "    sen = ascii_encode(text_to_encode, sentence_len)\n",
    "    \n",
    "    print(\"The image in which your message will be encoded will be shown now\")\n",
    "    plt.imshow(img[0], interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "    y = encoder.predict([img, sen])\n",
    "    print(\"The encoded image will be shown now\")\n",
    "    plt.imshow(y[0], interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    y_hat = decoder.predict(y)\n",
    "    print(\"The decrypted message is: \", ascii_decode(y_hat))\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e9a51-f7da-4518-89b8-ad444675aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Reshape, Conv2D, Concatenate, TimeDistributed, Dense\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import TensorSpec, float32, int32\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def rand_img(size):\n",
    "    return np.random.randint(0, 256, size).astype(np.float32) / 255.0\n",
    "\n",
    "def rand_sentence(len, max):\n",
    "    return np.random.randint(0, max, len).astype(np.int32)\n",
    "\n",
    "def one_hot_encoding(sentence, max):\n",
    "    msg = np.zeros((len(sentence), max), dtype=np.float32)\n",
    "    for i, v in enumerate(sentence):\n",
    "        msg[i, v] = 1.0\n",
    "    return msg\n",
    "\n",
    "def data_generator(image_size, sentence_len, sentence_max_word, batch_size=32):\n",
    "    while True:\n",
    "        x_img = np.zeros((batch_size, image_size[0], image_size[1], image_size[2]), dtype=np.float32)\n",
    "        x_sen = np.zeros((batch_size, sentence_len), dtype=np.int32)\n",
    "        y_img = np.zeros((batch_size, image_size[0], image_size[1], image_size[2]), dtype=np.float32)\n",
    "        y_sen = np.zeros((batch_size, sentence_len, sentence_max_word), dtype=np.float32)\n",
    "        for i in range(batch_size):\n",
    "            img = rand_img(image_size)\n",
    "            sentence = rand_sentence(sentence_len, sentence_max_word)\n",
    "            sentence_one_hot_encoded = one_hot_encoding(sentence, sentence_max_word)\n",
    "            x_img[i] = img\n",
    "            x_sen[i] = sentence\n",
    "            y_img[i] = img\n",
    "            y_sen[i] = sentence_one_hot_encoded\n",
    "        yield (x_img, x_sen), (y_img, y_sen)\n",
    "\n",
    "def get_model(image_shape, sentence_len, max_word):\n",
    "    input_img = Input(image_shape)\n",
    "    input_sen = Input((sentence_len,))\n",
    "    embed_sen = Embedding(max_word, 100)(input_sen)\n",
    "    flat_emb_sen = Flatten()(embed_sen)\n",
    "    flat_emb_sen = Dense(image_shape[0] * image_shape[1] * 3)(flat_emb_sen)\n",
    "    flat_emb_sen = Reshape((image_shape[0], image_shape[1], 3))(flat_emb_sen)\n",
    "    trans_input_img = Conv2D(20, 1, activation=\"relu\")(input_img)\n",
    "    enc_input = Concatenate(axis=-1)([flat_emb_sen, trans_input_img])\n",
    "    out_img = Conv2D(3, 1, activation='relu', name='image_reconstruction')(enc_input)\n",
    "    decoder_model = Sequential(name=\"sentence_reconstruction\")\n",
    "    decoder_model.add(Input(shape=(100, 100, 3)))\n",
    "    decoder_model.add(Conv2D(1, 1))\n",
    "    decoder_model.add(Reshape((sentence_len, 100)))\n",
    "    decoder_model.add(TimeDistributed(Dense(max_word, activation=\"softmax\")))\n",
    "    out_sen = decoder_model(out_img)\n",
    "    model = Model(inputs=[input_img, input_sen], outputs=[out_img, out_sen])\n",
    "    model.compile(optimizer='adam', loss=[MeanAbsoluteError(), CategoricalCrossentropy()],\n",
    "                  metrics={'sentence_reconstruction': CategoricalAccuracy()})\n",
    "    encoder_model = Model(inputs=[input_img, input_sen], outputs=[out_img])\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "def ascii_encode(message, sentence_len):\n",
    "    sen = np.zeros((1, sentence_len), dtype=np.int32)\n",
    "    for i, a in enumerate(message.encode(\"ascii\")):\n",
    "        sen[0, i] = a\n",
    "    return sen\n",
    "\n",
    "def ascii_decode(message):\n",
    "    return ''.join(chr(int(a)) for a in message[0].argmax(-1))\n",
    "\n",
    "def main():\n",
    "    image_shape = (100, 100, 3)\n",
    "    sentence_len = 100\n",
    "    max_word = 256\n",
    "    batch_size = 64\n",
    "    \n",
    "    gen = data_generator(image_shape, sentence_len, max_word, batch_size)\n",
    "    \n",
    "    output_signature = (\n",
    "        (TensorSpec(shape=(batch_size, *image_shape), dtype=float32),\n",
    "         TensorSpec(shape=(batch_size, sentence_len), dtype=int32)),\n",
    "        (TensorSpec(shape=(batch_size, *image_shape), dtype=float32),\n",
    "         TensorSpec(shape=(batch_size, sentence_len, max_word), dtype=float32))\n",
    "    )\n",
    "    \n",
    "    dataset = Dataset.from_generator(lambda: gen, output_signature=output_signature)\n",
    "    \n",
    "    model, encoder, decoder = get_model(image_shape, sentence_len, max_word)\n",
    "    try:\n",
    "        model.load_weights(\"best_weights.weights.h5\")\n",
    "    except:\n",
    "        model.fit(dataset, epochs=10, steps_per_epoch=100, callbacks=[\n",
    "            ModelCheckpoint(\"best_weights.weights.h5\", monitor=\"loss\",\n",
    "                            verbose=1,\n",
    "                            save_weights_only=True,\n",
    "                            save_best_only=True)]\n",
    "        )\n",
    "    \n",
    "    img_temp = Image.open(\"download.png\").convert(\"RGB\")  # Ensure image is in RGB format\n",
    "    res = img_temp.resize((100, 100))\n",
    "    img = np.expand_dims(img_to_array(res) / 255.0, axis=0)  # Normalized image array\n",
    "    \n",
    "    text_to_encode = input(\"Enter the code you want to encode: \")\n",
    "    sen = ascii_encode(text_to_encode, sentence_len)\n",
    "    \n",
    "    print(\"The image in which your message will be encoded will be shown now\")\n",
    "    plt.imshow(img[0], interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "    y = encoder.predict([img, sen])\n",
    "    print(\"The encoded image will be shown now\")\n",
    "    plt.imshow(y[0], interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    y_hat = decoder.predict(y)\n",
    "    print(\"The decrypted message is: \", ascii_decode(y_hat))\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
